{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple, List, Set, Iterator, Union\n",
    "import glob\n",
    "import argparse\n",
    "import shutil\n",
    "import multiprocessing as mp\n",
    "from detectron2.data import transforms as T\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import tifffile as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnoUtil:\n",
    "    \n",
    "    def __init__(self, annotation_file: str):\n",
    "\n",
    "        ##TODO: if annotation_file is None, handle error\n",
    "        \n",
    "        \"\"\"A class to hold image annotations with\n",
    "        convenience functions to parse various attributes\n",
    "        such as bounding box coordinates, annotation types, etc..\n",
    "\n",
    "        Args:\n",
    "        annotation_file -- full path to the json annotation\n",
    "        \"\"\"\n",
    "        with open(annotation_file) as jFile:\n",
    "            self.image_annotations = json.load(jFile)\n",
    "            \n",
    "    def search_recursive(self, d: Dict, key: str) -> Iterator:\n",
    "            \"\"\"Helper function for finding which level of json annotations has\n",
    "            the matching key.\n",
    "            \"\"\"\n",
    "            for k, v in d.items():\n",
    "                if isinstance(v, Dict):\n",
    "                    for match in self.search_recursive(v, key):\n",
    "                        yield match\n",
    "                if k == key:\n",
    "                    # generator function - saves in memory until called\n",
    "                    # (use for loop to call)\n",
    "                    yield v\n",
    "    \n",
    "    def find_bbox_coordinates(self, annotation_instance: Dict) -> Dict[str, List]:\n",
    "        \"\"\"Find and return the coordinates for an annotated bounding box.\n",
    "        Args:\n",
    "        annotation_instance -- annotation for one bounding box\n",
    "        Return:\n",
    "        bbox_dict -- A Dict of [ROI type, list of bbox coordinates in XYXY]\n",
    "        \"\"\"\n",
    "        box_name = self.get_box_name(annotation_instance)\n",
    "        # box_coord = annotation_instance[\"geometry\"][\"coordinates\"]\n",
    "        if box_name:\n",
    "            box_coord = next(self.search_recursive(annotation_instance, \"coordinates\"))\n",
    "            if len(box_coord) == 1: # Some polygons are broken into multiple sub-lists; this is a bandaid fix\n",
    "                box_arr = np.array(box_coord[0])\n",
    "                bbox = [\n",
    "                    min(box_arr[:, 0]),\n",
    "                    min(box_arr[:, 1]), \n",
    "                    max(box_arr[:, 0]),\n",
    "                    max(box_arr[:, 1]),\n",
    "                ]\n",
    "                bbox_dict = {box_name: bbox}\n",
    "                return bbox_dict\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def get_box_name(self, annotation_instance: Dict) -> str:\n",
    "        \"\"\"Find and return the name of an annotated bounding box.\n",
    "\n",
    "        Args:\n",
    "        annotation_instance -- annotation for one bounding box\n",
    "        Return:\n",
    "        box_name -- the annotated name of the box\n",
    "        \"\"\"\n",
    "        # Pass on polygons\n",
    "        num_vertices = len(next(self.search_recursive(annotation_instance, \"coordinates\"))[0])\n",
    "        if num_vertices > 5:\n",
    "            #print(\"passing\", num_vertices)\n",
    "            return None\n",
    "        else:\n",
    "            for properties in self.search_recursive(annotation_instance, \"properties\"):\n",
    "                if \"name\" in properties.keys():\n",
    "                    property_name = properties[\"name\"].upper()\n",
    "                    if \"ROI\" in property_name:\n",
    "                        cls_name = properties[\"classification\"][\"name\"].lower()\n",
    "                        box_name = f\"{property_name}_{cls_name}\"\n",
    "                    else:\n",
    "                        box_name = properties[\"name\"].lower()\n",
    "                    return box_name\n",
    "                else:\n",
    "                    return None\n",
    "                \n",
    "    def get_object_name(self, annotation_instance: Dict) -> str:\n",
    "        \"\"\"Find and return the name of an annotated mask.\n",
    "\n",
    "        Args:\n",
    "        annotation_instance -- annotation for one mask\n",
    "        Return:\n",
    "        mask_name -- the annotated name of the mask\n",
    "        \"\"\"\n",
    "        for properties in self.search_recursive(annotation_instance, \"properties\"):\n",
    "            if \"name\" in properties.keys():\n",
    "                property_name = properties[\"name\"].upper()\n",
    "                cls_name = properties[\"classification\"][\"name\"].lower()\n",
    "                mask_name = f\"{property_name}_{cls_name}\"\n",
    "            else:\n",
    "                mask_name = properties[\"name\"].lower()\n",
    "            return mask_name\n",
    "            \n",
    "    def find_poly_coordinates(self, annotation_instance: Dict)  -> Dict[str, List]:\n",
    "        \"\"\"Find and return the coordinates for an annotated polygon.\n",
    "        Args:\n",
    "        annotation_instance -- annotation for one polygon\n",
    "        Return:\n",
    "        poly_dict -- A Dict of [ROI type, list of polygon coordinates in XYXY pairs]\n",
    "        \"\"\"\n",
    "        poly_name = self.get_poly_name(annotation_instance)\n",
    "        if poly_name:\n",
    "            poly_coord = next(self.search_recursive(annotation_instance, \"coordinates\"))\n",
    "            poly_arr = np.array(poly_coord[0])\n",
    "            poly_dict = {poly_name: poly_arr}\n",
    "            return poly_dict\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def parse_bboxes(self) -> List[Dict]:\n",
    "        \"\"\"Parse bbox coordinates into detectron2's expected format: BoxMode.XYXY_ABS;\n",
    "        expect image_annotations in QuPath's exported format.\n",
    "        return:\n",
    "        bbox_list = a list of single-length dicts\n",
    "                    each dict's key is the classification\n",
    "                    each value is bbox coordinates in [XYXY]\n",
    "        \"\"\"\n",
    "        bbox_list = []\n",
    "        if not isinstance(self.image_annotations, list):\n",
    "            image_annotations = [self.image_annotations]\n",
    "        else:\n",
    "            image_annotations = self.image_annotations\n",
    "        for i in image_annotations:\n",
    "            bbox_dict = self.find_bbox_coordinates(i)\n",
    "            # Skip if no bbox_dict can be parsed\n",
    "            if not bbox_dict:\n",
    "                pass\n",
    "            # Check if key for bbox_dict is not None\n",
    "            elif list(bbox_dict.keys())[0]:\n",
    "                bbox_list.append(bbox_dict)\n",
    "        return bbox_list\n",
    "    \n",
    "    def parse_polygons(self) -> List[Dict]:\n",
    "        polygon_list = []\n",
    "        if not isinstance(self.image_annotations, list):\n",
    "            image_annotations = [self.image_annotations]\n",
    "        else:\n",
    "            image_annotations = self.image_annotations\n",
    "        for i in image_annotations:\n",
    "            poly_dict = self.find_poly_coordinates(i)\n",
    "            # Skip if no poly_dict can be parsed\n",
    "            if not poly_dict:\n",
    "                pass\n",
    "            # Check if key for poly_dict is not None\n",
    "            elif list(poly_dict.keys())[0]:\n",
    "                polygon_list.append(poly_dict)\n",
    "        return polygon_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lymph_nonlymph_annos(anno_path: str, scale_factor: float) -> List:\n",
    "    #get lymph and non-lymph annotations\n",
    "    anno_helper = AnnoUtil(anno_path)\n",
    "    bbox_dicts = anno_helper.parse_bboxes()\n",
    "    anno_list = []\n",
    "    for i in bbox_dicts:\n",
    "        try:\n",
    "            lymph_coords = [int(x * scale_factor) for x in i['lymph']]\n",
    "            lymph_dict = {'lymph' : lymph_coords}\n",
    "            anno_list.append(lymph_dict)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            nonlymph_coords = [int(x * scale_factor) for x in i['non-lymph']]\n",
    "            nonlymph_dict = {'non-lymph' : nonlymph_coords}\n",
    "            anno_list.append(nonlymph_dict)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return anno_list\n",
    "\n",
    "def class_conversion_annos(class_path: str, anno_path: str, scale_factor: float) -> List:\n",
    "    # get all annos that exist in class conversions file \n",
    "    with open(class_path) as f:\n",
    "        class_conversions = json.load(f)\n",
    "    anno_helper = AnnoUtil(anno_path)\n",
    "    polygon_dicts = anno_helper.parse_polygons()\n",
    "    anno_list = []\n",
    "    for i in polygon_dicts:\n",
    "        try:\n",
    "            for key in i.keys():\n",
    "                if key in class_conversions.keys():\n",
    "                    coords = [int(x * scale_factor) for x in i[key]]\n",
    "                    anno_dict = {class_conversions[key] : coords}\n",
    "                    anno_list.append(anno_dict)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def channel_last(input: np.ndarray or tuple) -> np.ndarray or tuple:\n",
    "    \"\"\"Return the input in channel-last format\n",
    "    Args:\n",
    "    input -- np.ndarray if image or tuple of array.shape\n",
    "    Return:\n",
    "    image as ndarray but in channel-last (h, w, c)\n",
    "    \"\"\"\n",
    "    if type(input) == np.ndarray:\n",
    "        if input.shape[0] == 3:\n",
    "            return input.transpose(1, 2, 0)\n",
    "        else:\n",
    "            return input\n",
    "    if type(input) == tuple:\n",
    "        if input[0] == 3:\n",
    "            return tuple(input[i] for i in [1, 2, 0])\n",
    "        else:\n",
    "            return input\n",
    "        \n",
    "def resize_image(image, max_dim):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    image -- np.ndarray with shape (h, w, c)\n",
    "    Return:\n",
    "    resized_image -- np.ndarray with shape (h, w, c)\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    scale_factor = max_dim / max(h, w)\n",
    "    new_h = int(h * scale_factor)\n",
    "    new_w = int(w * scale_factor)\n",
    "    resized_image = T.ResizeTransform(h, w, new_h, new_w).apply_image(image)\n",
    "    return resized_image, scale_factor\n",
    "\n",
    "def vis_image_with_annos(image, annotations, output):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image)\n",
    "    for anno in annotations:\n",
    "        for name, box in anno.items():\n",
    "            x1, y1, x2, y2 = box\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            rect = patches.Rectangle(\n",
    "                (x1, y1),\n",
    "                w, h,\n",
    "                linewidth=1,\n",
    "                edgecolor='r',\n",
    "                facecolor='none'\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            ax.annotate(name, (x1, y1), color='b')\n",
    "        fig.savefig(output)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_bboxes(bboxes: list, ref_dim, target_dim):\n",
    "    \"\"\"Scale bounding boxes in XYXY\n",
    "    \n",
    "    Args:\n",
    "    bboxes -- a list of bboxes in the form [XYXY]\n",
    "    ref_dim -- (h, w, c) or (h, w)\n",
    "    target_dim -- ((h, w, c) or (h, w))\n",
    "    Return:\n",
    "    scaled_bboxes -- a list of scaled [XYXY]\n",
    "    \"\"\"\n",
    "    x_scale = ref_dim[1] / target_dim[1]\n",
    "    y_scale = ref_dim[0] / target_dim[0]\n",
    "    scaled_bboxes = []\n",
    "    for box in bboxes:\n",
    "        x0 = int(box[0] / x_scale)\n",
    "        y0 = int(box[1] / y_scale)\n",
    "        x1 = int(box[2] / x_scale)\n",
    "        y1 = int(box[3] / y_scale)\n",
    "        scaled_bboxes.append([x0, y0, x1, y1])\n",
    "    return scaled_bboxes\n",
    "\n",
    "def scale_polygons(polygons: list, ref_dim, target_dim):\n",
    "    \"\"\"Scale polygons in XYXY\n",
    "    \n",
    "    Args:\n",
    "    polygons -- a list of polygons in the form [XYXY]\n",
    "    ref_dim -- (h, w, c) or (h, w)\n",
    "    target_dim -- ((h, w, c) or (h, w))\n",
    "    Return:\n",
    "    scaled_polygons -- a list of scaled [XYXY]\n",
    "    \"\"\"\n",
    "    x_scale = ref_dim[1] / target_dim[1]\n",
    "    y_scale = ref_dim[0] / target_dim[0]\n",
    "    scaled_polygons = []\n",
    "    for poly in polygons:\n",
    "        scaled_poly = []\n",
    "        for point in poly:\n",
    "            x = int(point[0] / x_scale)\n",
    "            y = int(point[1] / y_scale)\n",
    "            scaled_poly.append(x)\n",
    "            scaled_poly.append(y)\n",
    "        scaled_polygons.append(scaled_poly)\n",
    "    return scaled_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(out_dir, img_file, anno_file, **kwargs):\n",
    "    try:\n",
    "        img_name = os.path.basename(img_file).split('.')[0]\n",
    "        print(f\"Processing {img_name}...\")\n",
    "        # Find matching annotation json\n",
    "        max_dim = 2560\n",
    "        #rescale image so that the longest edge is max_dim\n",
    "        with tf.TiffFile(img_file) as tiff:\n",
    "            lvl = 1 #TODO:by default, make this an option\n",
    "            pyramid_reader = tiff.series[0].levels\n",
    "            img = pyramid_reader[lvl].asarray()\n",
    "            if img_file.endswith('.tif'):\n",
    "                correct_dimensions = (tiff.pages[0].shape[0])\n",
    "                img = channel_last(img)\n",
    "            #rescale img to max_dim as longest edge\n",
    "            img, scaling = resize_image(img, max_dim)\n",
    "            true_scale = scaling / 4 #TODO: unhardcode this\n",
    "            annos = lymph_nonlymph_annos(anno_file, true_scale)\n",
    "        #write img_name and true_scale to disk\n",
    "        if not os.path.exists(os.path.join(out_dir, 'tissue_scale')):\n",
    "            os.makedirs(os.path.join(out_dir, 'tissue_scale'))\n",
    "        with open(os.path.join(out_dir, 'tissue_scale', img_name + '_scaling.json'), 'w') as f:\n",
    "            f.write(str(true_scale))\n",
    "        \n",
    "        tissue_anno_dict = {\n",
    "            'file_name' : img_file,\n",
    "            'pyramid_level' : lvl,\n",
    "            'image_width' : img.shape[1],\n",
    "            'image_height' : img.shape[0],\n",
    "            'max_dim' : max_dim,\n",
    "            'box_dicts' : annos\n",
    "        }\n",
    "\n",
    "        anno_json = json.dumps(tissue_anno_dict, indent=4)\n",
    "        with open(os.path.join(out_dir, 'tissue_annotations', img_name +'.json'), 'w') as j:\n",
    "            j.write(anno_json)\n",
    "        if 'visualize' in kwargs.keys():\n",
    "            vis_file = img_name + '.png'\n",
    "            vis_out_dir = os.path.join(out_dir, 'data_vis')\n",
    "            vis_image_with_annos(\n",
    "                img,\n",
    "                annos,\n",
    "                os.path.join(vis_out_dir, vis_file))\n",
    "\n",
    "        # save image as numpy array\n",
    "        with open(os.path.join(out_dir, img_name + '.npy'), 'wb') as f:\n",
    "            np.save(os.path.join(out_dir, img_name + '.npy'), img)\n",
    "        \n",
    "    except:\n",
    "        print(f\"Cannot process {img_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/mnt/voyage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/chao_lab/SynologyDrive/chaolab_AI_path/tissue_finder2/TissueAnnotatorSingleThread.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/tissue_finder2/TissueAnnotatorSingleThread.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m in_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/mnt/voyage/Datasets_pathology/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCam16_test\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/tissue_finder2/TissueAnnotatorSingleThread.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(out_dir, \u001b[39m'\u001b[39m\u001b[39mtissue_annotations\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/tissue_finder2/TissueAnnotatorSingleThread.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     os\u001b[39m.\u001b[39;49mmakedirs(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(out_dir, \u001b[39m'\u001b[39;49m\u001b[39mtissue_annotations\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/tissue_finder2/TissueAnnotatorSingleThread.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m img_files \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(glob\u001b[39m.\u001b[39mglob(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(in_dir, \u001b[39m'\u001b[39m\u001b[39m*.tif\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/tissue_finder2/TissueAnnotatorSingleThread.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m anno_files \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(glob\u001b[39m.\u001b[39mglob(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(in_dir, \u001b[39m'\u001b[39m\u001b[39mqupath_annotations_latest\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m*.json\u001b[39m\u001b[39m'\u001b[39m)))\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_path/lib/python3.9/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m head \u001b[39mand\u001b[39;00m tail \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         makedirs(head, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n\u001b[1;32m    216\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[39m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_path/lib/python3.9/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m head \u001b[39mand\u001b[39;00m tail \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         makedirs(head, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n\u001b[1;32m    216\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[39m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: makedirs at line 215 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_path/lib/python3.9/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m head \u001b[39mand\u001b[39;00m tail \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         makedirs(head, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n\u001b[1;32m    216\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[39m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_path/lib/python3.9/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/mnt/voyage'"
     ]
    }
   ],
   "source": [
    "out_dir = '/home/chao_lab/GT_2023/TissueFinderV2/' + 'Cam16_17'\n",
    "in_dir = '/mnt/voyage/Datasets_pathology/' + 'Cam16_test'\n",
    "\n",
    "if not os.path.exists(os.path.join(out_dir, 'tissue_annotations')):\n",
    "    os.makedirs(os.path.join(out_dir, 'tissue_annotations'))\n",
    "\n",
    "img_files = sorted(glob.glob(os.path.join(in_dir, '*.tif')))\n",
    "anno_files = sorted(glob.glob(os.path.join(in_dir, 'qupath_annotations_latest', '*.json')))\n",
    "\n",
    "for i in range(len(img_files)):\n",
    "    main(out_dir, img_files[i], anno_files[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_path",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
