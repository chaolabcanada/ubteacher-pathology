{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacky way to resolve project paths\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(os.getcwd()).parents[0]))\n",
    "sys.path.append(str(Path(os.getcwd()).parents[1]))\n",
    "\n",
    "import json\n",
    "from ubteacher import add_ubteacher_config\n",
    "from detectron2.config import get_cfg\n",
    "from typing import Dict, Set, List, Tuple, Iterator\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tf\n",
    "from detectron2.engine import default_argument_parser, default_setup, launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan: use qupath_annotations_latest instead of TissueAnnotator outputs for loading -- consistency across datasets and easier to use.\n",
    "1. Load only information relevant to the task at hand from json\n",
    "2. Load npy files for each image from dir, with option to create\n",
    "3. Register the dataset\n",
    "4. Idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ubteacher.utils.train2_utils import (get_scaling, ParseFromQuPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple, List, Set, Iterator\n",
    "import json\n",
    "import glob\n",
    "from detectron2.data import transforms as T\n",
    "import tifffile as tf\n",
    "\n",
    "\n",
    "def select_annotypes(anno_dir: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Select annotation types to include\n",
    "    \"\"\"\n",
    "    annotypes = []\n",
    "    possible_tissues = []\n",
    "    for f in glob.glob(os.path.join(anno_dir, '*.json')):\n",
    "        with open(f, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        for i in data:\n",
    "            try:\n",
    "                if i['geometry']['type'] == 'Polygon':\n",
    "                    possible_tissues += [next(search_recursive(i, 'name'))]\n",
    "                    possible_tissues = list(set(t.split(' ')[0] for t in possible_tissues))\n",
    "            except:\n",
    "                pass\n",
    "    print(f'Found {set(possible_tissues)} tissue types with valid annotations')\n",
    "    selected_tissues = input('Select tissue types to train on (comma separated)')\n",
    "    tissue_types = selected_tissues.split(',')\n",
    "    print(f'Selected tissue types: {tissue_types}')\n",
    "    annotypes.extend(tissue_types)\n",
    "    return annotypes\n",
    "        \n",
    "def find_anno_dir(parent_dir: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Find qupath exported annotations directory\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.path.exists(os.path.join(parent_dir, 'xupath_annotations_latest')):\n",
    "        return os.path.join(parent_dir, 'qupath_annotations_latest')\n",
    "    else:\n",
    "        anno_dirs = []\n",
    "        for root, dirs, files in os.walk(parent_dir):\n",
    "            for d in dirs:\n",
    "                if 'annotations' in d:\n",
    "                    anno_dirs.append(os.path.join(root, d))\n",
    "        # user chooses if there are multiple annotation folders\n",
    "        print('Found multiple annotation folders:')\n",
    "        for i, anno_dir in enumerate(anno_dirs):\n",
    "            print(f'{i}: {os.path.relpath(anno_dir, parent_dir)}')\n",
    "        choice = input('Choose annotation folder index')\n",
    "        if choice.isdigit() and int(choice) < len(anno_dirs):\n",
    "            return anno_dirs[int(choice)]    \n",
    "        else:\n",
    "            raise ValueError('Annotation folder not found')\n",
    "        \n",
    "def find_img_dir(parent_dir: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Find npy image directory for training\n",
    "    \"\"\"\n",
    "    img_dirs = []\n",
    "    for root, dirs, files in os.walk(parent_dir):\n",
    "        for d in dirs:\n",
    "            if glob.glob(os.path.join(root, d, '*.npy')):\n",
    "                img_dirs.append(os.path.join(root, d))\n",
    "    # user chooses if there are multiple img folders\n",
    "    for i, img_dir in enumerate(img_dirs):\n",
    "        print(f'{i}: {os.path.relpath(img_dir, parent_dir)}')\n",
    "    choice = input('Choose image folder index')\n",
    "    if choice.isdigit() and int(choice) < len(img_dirs):\n",
    "        return img_dirs[int(choice)]\n",
    "    else:\n",
    "        raise ValueError('Image folder not found')\n",
    "        \n",
    "def search_recursive(d: Dict, key: str) -> Iterator:\n",
    "        \"\"\"Helper function for finding which level of json annotations has\n",
    "        the matching key.\n",
    "        \"\"\"\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, Dict):\n",
    "                for match in search_recursive(v, key):\n",
    "                    yield match\n",
    "            if k == key:\n",
    "                # generator function - saves in memory until called\n",
    "                # (use for loop to call)\n",
    "                yield v\n",
    "    \n",
    "def get_scaling(original_file, output_file):\n",
    "        with tf.TiffFile(original_file) as tiff:\n",
    "            # get base size\n",
    "            base_dim = tiff.pages[0].shape[:2]\n",
    "            print(f'Image size: {base_dim}') #TODO: remove\n",
    "    \n",
    "        f = np.load(output_file)\n",
    "        target_dim = f.shape[:2]\n",
    "        del f # use del instead of with because numpy version issue\n",
    "        print(f'Image size: {target_dim}') #TODO: remove\n",
    "        return base_dim, target_dim\n",
    "\n",
    "class ParseFromQuPath:\n",
    "    \n",
    "    def __init__(self, ref_dim, target_dim, tissue_types):\n",
    "        self.anno_dir = '/mnt/RSX/Datasets_pathology/SRI_OSCC_lymph_labeled/qupath_annotations_latest'\n",
    "        self.img_dir = '/mnt/RSX/Datasets_pathology/GT_2023/TissueFinderV2/SRI_OSCC'\n",
    "        self.ref_dim = ref_dim\n",
    "        self.target_dim = target_dim\n",
    "        self.tissue_types = tissue_types\n",
    "            \n",
    "    def scale_bboxes_qupath(self, anno):\n",
    "        x_scale = self.ref_dim[1] / self.target_dim[1]\n",
    "        y_scale = self.ref_dim[0] / self.target_dim[0]\n",
    "        for i in anno:\n",
    "            [coords] = i['coordinates']\n",
    "            # First, build XYXY\n",
    "            x0 = int(coords[0][0] / x_scale)\n",
    "            y0 = int(coords[0][1] / y_scale)\n",
    "            x1 = int(coords[2][0] / x_scale)\n",
    "            y1 = int(coords[2][1] / y_scale)\n",
    "            i['bbox'] = [x0, y0, x1, y1]\n",
    "            del i['coordinates']\n",
    "            # make it as 'bbox': asdjhkf\n",
    "        return anno\n",
    "        \n",
    "    def get_boxes(self, json_file):\n",
    "        \n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        tissue_data = []\n",
    "            \n",
    "        for i in data:\n",
    "            if any(tissue in list(search_recursive(i, 'name')) for tissue in self.tissue_types):\n",
    "                tissue_data.append(i)\n",
    "        cat_map = {tissue: i for i, tissue in enumerate(self.tissue_types)}\n",
    "        coords = []\n",
    "        for k in tissue_data:\n",
    "            ## add names to k \n",
    "            k['geometry']['category_id'] = cat_map[next(search_recursive(k, 'name'))]\n",
    "            del k['geometry']['type']\n",
    "            k['geometry']['bbox_mode'] = 0\n",
    "            coords.append(next(search_recursive(k, 'geometry')))\n",
    "        \n",
    "        out = self.scale_bboxes_qupath(coords)\n",
    "        \n",
    "        return out, cat_map\n",
    "\n",
    "    def get_coco_format(self, json_file):\n",
    "        \n",
    "        \"\"\"\n",
    "        Get coco format for detectron2\n",
    "        \"\"\"\n",
    "        ## Determine image format\n",
    "        img_base = os.path.basename(os.path.splitext(json_file)[0])\n",
    "        img_fname = os.path.join(self.img_dir, img_base) + '.npy'\n",
    "        \n",
    "        ## Get annotation data\n",
    "        \n",
    "        annotation_dicts, cat_map = self.get_boxes(json_file)\n",
    "        \n",
    "        ## Fill remaining fields\n",
    "        \n",
    "        dataset_dicts = [{'file_name': img_fname,\n",
    "                        'height': self.target_dim[0],\n",
    "                        'width': self.target_dim[1],\n",
    "                        'image_id': img_base,\n",
    "                        'annotations': annotation_dicts}\n",
    "                        ]  \n",
    "\n",
    "        return dataset_dicts, cat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found {'ROI_neoplastic', 'Primary', 'multinucleated_cells', 'Lymphoid', 'no', 'No', 'keratin', 'Necrosis', 'Parotid', 'ROI', 'non-neoplastic', 'non-lymph', 'Non-neoplastic', 'primary', 'skeletal', 'oral', 'Salivary', 'parotid', 'Tumor', 'Keratin', 'Submandibular', 'ROI_non-neoplastic', 'lymph'} tissue types with valid annotations\n",
      "Selected tissue types: ['non-lymph']\n"
     ]
    }
   ],
   "source": [
    "classes = select_annotypes('/mnt/RSX/Datasets_pathology/SRI_OSCC_lymph_labeled/qupath_annotations_latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (33709, 39839)\n",
      "Image size: (2166, 2560)\n",
      "[{'type': 'Feature', 'id': 'aa9492b8-58bb-490f-acf4-52625979f76a', 'geometry': {'type': 'Polygon', 'coordinates': [[[14701, 1589], [39083, 1589], [39083, 27357], [14701, 27357], [14701, 1589]]]}, 'properties': {'objectType': 'annotation', 'name': 'non-lymph', 'classification': {'name': 'oral', 'color': [176, 50, 232]}}}, {'type': 'Feature', 'id': '328e55f2-31a1-4135-bce1-442798f103be', 'geometry': {'type': 'Polygon', 'coordinates': [[[1629, 10865], [21905, 10865], [21905, 32764], [1629, 32764], [1629, 10865]]]}, 'properties': {'objectType': 'annotation', 'name': 'non-lymph', 'classification': {'name': 'oral', 'color': [176, 50, 232]}}}]\n",
      "{'non-lymph': 0}\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'k' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m json_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/mnt/RSX/Datasets_pathology/SRI_OSCC_lymph_labeled/qupath_annotations_latest/Case 1 G7.json\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m base_dim, target_dim \u001b[39m=\u001b[39m get_scaling(original_file, output_file)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m dataset_dicts, cat_map \u001b[39m=\u001b[39m ParseFromQuPath(base_dim, target_dim, classes)\u001b[39m.\u001b[39;49mget_coco_format(json_file)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(dataset_dicts)\n",
      "\u001b[1;32m/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=154'>155</a>\u001b[0m img_fname \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_dir, img_base) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.npy\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=156'>157</a>\u001b[0m \u001b[39m## Get annotation data\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=158'>159</a>\u001b[0m annotation_dicts, cat_map \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_boxes(json_file)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=160'>161</a>\u001b[0m \u001b[39m## Fill remaining fields\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=162'>163</a>\u001b[0m dataset_dicts \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m'\u001b[39m: img_fname,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=163'>164</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mheight\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_dim[\u001b[39m0\u001b[39m],\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=164'>165</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_dim[\u001b[39m1\u001b[39m],\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=165'>166</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mimage_id\u001b[39m\u001b[39m'\u001b[39m: img_base,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=166'>167</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mannotations\u001b[39m\u001b[39m'\u001b[39m: annotation_dicts}\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=167'>168</a>\u001b[0m                 ]  \n",
      "\u001b[1;32m/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=132'>133</a>\u001b[0m \u001b[39mprint\u001b[39m(tissue_data)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=133'>134</a>\u001b[0m \u001b[39mprint\u001b[39m(cat_map)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=134'>135</a>\u001b[0m \u001b[39mprint\u001b[39m(cat_map[\u001b[39mnext\u001b[39m(search_recursive(k, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m))])\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=135'>136</a>\u001b[0m coords \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m tissue_data:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252535f50726f78794a756d70227d/home/chao_lab/SynologyDrive/chaolab_AI_path/unbiased_teacher2/notebooks/train_net2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=137'>138</a>\u001b[0m     \u001b[39m## add names to k \u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'k' referenced before assignment"
     ]
    }
   ],
   "source": [
    "original_file = '/mnt/RSX/Datasets_pathology/SRI_OSCC_lymph_labeled/images/Case 1 G7.svs'\n",
    "output_file = '/mnt/RSX/Datasets_pathology/GT_2023/TissueFinderV2/SRI_OSCC_lymph_labeled/Case 1 G7.npy'\n",
    "json_file = '/mnt/RSX/Datasets_pathology/SRI_OSCC_lymph_labeled/qupath_annotations_latest/Case 1 G7.json'\n",
    "\n",
    "base_dim, target_dim = get_scaling(original_file, output_file)\n",
    "dataset_dicts, cat_map = ParseFromQuPath(base_dim, target_dim, classes).get_coco_format(json_file)\n",
    "print(dataset_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'file_name': '/mnt/RSX/Datasets_pathology/GT_2023/TissueFinderV2/SRI_OSCC/Case 1 G7.npy', 'height': 2166, 'width': 2560, 'image_id': 'Case 1 G7', 'annotations': [{'category_id': 1, 'bbox_mode': 0, 'bbox': [944, 102, 2511, 1757]}, {'category_id': 1, 'bbox_mode': 0, 'bbox': [104, 698, 1407, 2105]}]}]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lymph': 0, 'non-lymph': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(args):\n",
    "    \"\"\"\n",
    "    Create configs and perform basic setups.\n",
    "    \"\"\"\n",
    "    cfg = get_cfg()\n",
    "    cfg.set_new_allowed(True) #allows custom cfg keys\n",
    "    add_ubteacher_config(cfg)\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "    cfg.merge_from_list(args.opts)\n",
    "    cfg.freeze()\n",
    "    default_setup(cfg, args)\n",
    "    \n",
    "def main(args):\n",
    "    \n",
    "    cfg = setup(args)\n",
    "    anno_dir = find_anno_dir(cfg.ANNO_DIR)\n",
    "    img_dir = find_img_dir(cfg.IMG_DIR)\n",
    "    try:\n",
    "        classes = cfg.DATASET.CLASSES\n",
    "    except:\n",
    "        classes = select_annotypes(anno_dir)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    args = default_argument_parser().parse_args()\n",
    "\n",
    "    print(\"Command Line Args:\", args)\n",
    "    launch(\n",
    "        main,\n",
    "        args.num_gpus,\n",
    "        num_machines=args.num_machines,\n",
    "        machine_rank=args.machine_rank,\n",
    "        dist_url=args.dist_url,\n",
    "        args=(args,),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_path",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
